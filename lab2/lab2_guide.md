# <div align="center"> Продолжаем разворачивать


## <div align="center"> Intro 

В прошлой лабораторной работе мы поняли что такое контейнер, откуда его брать и как запускать. Теперь задача несколько сложнее - научиться запускать несколько контейнеров за раз так, чтобы они могли друг с другом коммуницировать.

В репозитории приведена система из 3 контейнеров:
- producer1
- producer2
- consumer

Producer-ы - контейнеры, которые производят данные. Условная эмуляция каких - нибудь датчиков ~~(по заветам В. Г. Иваненко)~~, которые меряют данные в реальном времени и отправляют их на сервер. У сервера же стоит невероятно сложная вичислительная задача - перемножить 2 матрицы (данные для которых и отсылают producer-ы).

Рассмотрим эти програмы поподробнее.

**producer.go** использует стандартную библиотеку http для отправки POST запросов на сервер. Если с Go вы столкнулись впервые, то в папке dev есть почти аналогичная программа на более распространённом языке python.

Фактически алгоритм заключается в следующем:
- сформировать запрос из типа producer-а и случайного числа
- отправить его на сервер
- проверить, не произло ли ошибки при отправке и что сервер корректо его обработал
- после отправки всех сообщений, послать сообщение об окончании отправки

**consumer.cpp** использует микрофреймворк Crow, чтобы обрабатывать запросы. С++ нам знаком, а по фреймворку есть [подробный мануал на официальном сайте](https://crowcpp.org/master/). 

Алгоритм обработчика ещё проще:
- пока не пришло сообщение об окончании отправки, принимаем и записываем в память.
- пришло сообщение об окончании - обрабатываем данные.

Остальные файлы - необходимые .h для Crow и Dockerfile для запуска каждого из перечисленных выше приложений.

#### Это мы уже видели:
- consumer/Dockerfile
- producer1/Dockerfile
- producer2/Dockerfile

Для .cpp использум Debian за основу. Для .go официальные образы Go.

Каждый из контейнеров мы можем запустить отдельно. Как это сделать, объяснялось в первой лабораторной. Только для контейнеров producer необходимо указывать переменную окружения MSize: **sudo docker run -e MSize=10 producer**. (Контейнер был собран с именем producer)

А вот **docker-compose.yaml** что-то новое.

## <div align="center"> docker compose 

Docker Compose (**DC** далее в гайде) - это инструмент, который позволяет определять и управлять многоконтейнерными приложениями в Docker. Он использует файл формата YAML для настройки сервисов, сетей и томов, необходимых для вашего приложения. С помощью Docker Compose вы можете определить связи между различными контейнерами и легко управлять их конфигурацией и развертыванием.

Используя Docker Compose, вы можете определить сервисы, сети и тома вашего приложения в едином файле, что упрощает управление и развертывание приложения в различных средах. Он предоставляет простый и декларативный синтаксис для определения инфраструктуры вашего приложения, что упрощает сотрудничество с другими разработчиками.

Продробно про **DC** можно прочесть на [официальном сайте](https://docs.docker.com/compose/).

Docker compose файл начинается со строчки **version**. Она отвечает за версию синтаксиса. **V1** - устаревшая и больше не поддерживается.

version: '3' - указывает версию Docker Compose, используемую в файле.

Далее структура иерархическая:
- servies: # начало секции, где определяются сервисы (контейнеры) для запуска.
  - prodecer1: # имя сервиса (контейнера) producer1.
    - build: # определяет настройки для сборки контейнера.
      - context: # указывает путь к директории с Dockerfile для сборки контейнера
      - no_cache: true # отключает кэширование при сборке контейнера producer1.
    - env_file: # указывает файлы с переменными окружения, которые будут загружены в контейнер producer1. 
    - networks: # определяет сети, к которым будет присоединен контейнер producer1.
  -
  -
    - resources: # определяет ресурсы, выделенные для контейнера consumer.
      - limits: - определяет ограничения ресурсов, в данном случае, CPU.
- networks: # начало секции, где определяются сети, используемые в приложении.
  - lab2network: # имя сети, в данном случае, lab2network.

Для запуска используется команда **docker compose up**.

После неё вы должы увидеть в терминале сообщения от producer-ов об отправке сообщений. В какой - то момент темп отправки сильно упадёт, могут появится ошибки подключения к consumer-у. 